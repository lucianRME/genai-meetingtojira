# ðŸ¤– GenAI Requirements & BDD Generator (POC)

> ðŸ“ **Meeting Transcript â†’ Requirements + Test Cases â†’ Approve â†’ Export to Jira**

This repository is a **Proof of Concept (POC)** showing how **GenAI can automate requirement engineering and QA** â€” converting real meeting transcripts (e.g., from Microsoft Teams) into:

- ðŸ“‹ **Requirements (user stories)**
- âœ… **BDD / Gherkin test cases**
- ðŸ–¥ï¸ **Manual approval UI**
- ðŸ“¤ **CSV export for Jira**

---

## ðŸŒ Overview

This POC demonstrates an **end-to-end (E2E)** AI-driven flow from raw meeting data to testable, traceable requirements â€” using OpenAI models and structured persistence.

| Step | Description |
|------|--------------|
| 1ï¸âƒ£ | Ingests `.vtt` meeting transcripts |
| 2ï¸âƒ£ | Filters small-talk and irrelevant lines (rule-based + optional LLM classifier) |
| 3ï¸âƒ£ | Extracts structured business requirements |
| 4ï¸âƒ£ | Generates **3 BDD test cases per requirement** (positive, negative, regression) |
| 5ï¸âƒ£ | Persists results to **SQLite (repo.db)** and **JSON (output.json)** |
| 6ï¸âƒ£ | Optionally exports to **CSV â†’ Jira import** |
| 7ï¸âƒ£ | Ready for multi-agent orchestration and analytics |

---

## ðŸ” API Key Setup

Youâ€™ll need an OpenAI API key.

1. Go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
2. Click **Create new secret key** and copy it (`sk-...`)
3. Create a file `.env` in the project root with:

```
OPENAI_API_KEY=sk-YOUR-KEY-HERE
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.2

# Optional toggles
SMALLTALK_FILTER=1
SMALLTALK_LLM_CLASSIFIER=0
SMALLTALK_CLASSIFIER_MODEL=gpt-4o-mini

# File paths
TRANSCRIPT_FILE=meeting_transcript.vtt
OUTPUT_DIR=output
OUTPUT_BASENAME=demo_run
```

---

## âš™ï¸ Architecture

```mermaid
flowchart TD
    A[Meeting Transcript (.vtt)] --> B[generate_req_bdd.py<br>Run Pipeline]
    B -->|OpenAI API| C[Requirements + BDD Test Cases]
    C --> D[(repo.db)]
    C --> E[output.json]
    D --> F[Flask UI app.py<br>Manual Approval]
    F --> D
    D --> G[export_csv.py]
    G --> H[CSV for Jira]
    B --> I[run_pipeline.py<br>E2E Controller]
```

---

## ðŸš€ How to Run

### ðŸ§© 1. Install dependencies
```
pip install -r requirements.txt
```

### â–¶ï¸ 2. Run the full E2E pipeline
```
python run_pipeline.py
```

This will:
- Read your `meeting_transcript.vtt`
- Generate structured requirements + test cases
- Persist results in `output.json` and `repo.db`
- Export CSVs via `export_csv.py` (if present)
- Print a clean summary of results

You can also specify another transcript manually:
```
python generate_req_bdd.py path/to/another_transcript.vtt
```

---

## ðŸ§± Repository Structure

```
.
â”œâ”€â”€ generate_req_bdd.py      # Core LLM pipeline (requirements + BDD)
â”œâ”€â”€ run_pipeline.py          # E2E orchestrator (1-click flow)
â”œâ”€â”€ export_csv.py            # CSV / Jira export
â”œâ”€â”€ app.py                   # Optional Flask UI for approvals
â”œâ”€â”€ meeting_transcript.vtt   # Example transcript input
â”œâ”€â”€ output.json              # LLM output artifact
â”œâ”€â”€ repo.db                  # SQLite persistence layer
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ output/                  # Demo CSV outputs
```

---

## ðŸ§  Recent Improvements (v2 â€“ Agentic Ready)

### ðŸ”„ Core Script (`generate_req_bdd.py`)
- Refactored into `run_pipeline()` callable for orchestration  
- Deterministic sequential IDs (`REQ-001`, `REQ-002`, â€¦)  
- Exactly 3 acceptance criteria per requirement (pads/trims automatically)  
- Robust JSON parsing and fallback recovery  
- Normalized single-line Gherkin output  
- Graceful handling of empty transcripts  
- Same schema compatibility (`output.json`, `repo.db`)

### ðŸš€ New Orchestrator (`run_pipeline.py`)
- Single command to run the entire flow  
- Auto-calls `generate_req_bdd.py`  
- Optionally triggers `export_csv.py`  
- Outputs demo CSVs in `/output`  
- Prints clear metrics + file paths  
- Foundation for multi-agent control loop  

---

## ðŸ“Š Example Output

**Console summary**
```
ðŸ“‹ Extracted 5 requirements:
- REQ-001 Login authentication
- REQ-002 Password reset
...
âœ… Generated 15 test cases (15 valid Gherkin)
ðŸŽ¯ Done. Lines kept: 210/248 (classifier=off)
ðŸš€ E2E DONE
ðŸ§© requirements: 5
âœ… test cases:   15
ðŸ“¦ outputs:      output.json , repo.db
ðŸ“‘ csv:          output/demo_run_requirements.csv , output/demo_run_test_cases.csv
```

---

## ðŸ§© Next Steps
- Add **ReviewAgent** for validation and deduplication  
- Integrate **Jira API** for direct issue creation  
- Add **MetricsAgent** for baseline vs improved runs  
- Parallelize per-chunk LLM calls  
- Extend UI for â€œApprove â†’ Export â†’ Sync to Jiraâ€

---

## ðŸ’¡ Vision
> This POC shows how GenAI can move beyond text generation â€”  
> becoming an **autonomous system for requirements engineering**  
> that improves over time, validates itself, and connects directly to delivery tools.